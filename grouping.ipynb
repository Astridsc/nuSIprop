{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2\n",
    "from scipy.interpolate import interp1d\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/astridaurora/HESE-7-year-data-release/HESE-7-year-data-release')\n",
    "from Astrid.effective_area import bin_edges_to_centers, bin_centers_to_edges, apply_energy_smearing\n",
    "\n",
    "import nuSIprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is for larger datasets where one can use the Chi2 computations for Gaussian distributions with larger n, or when one wants to avoid the x_i=zero numerical divergence by grouping the events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chi2(observed, expected, err=None):\n",
    "    \"\"\"\n",
    "    Compute the Chi-squared statistic between two DataFrames.\n",
    "    \n",
    "    Parameters:\n",
    "    observed : array-like\n",
    "        Observed values.\n",
    "    expected : array-like\n",
    "        Expected values. Must have the same shape as observed.\n",
    "    \n",
    "    Returns:\n",
    "    chi2_value : float\n",
    "        The chi-squared value.\n",
    "    p_value : float\n",
    "        The p-value corresponding to the chi-squared test.\n",
    "    \"\"\" \n",
    "    # Ensure DataFrames have the same shape\n",
    "    if observed.shape != expected.shape:\n",
    "        raise ValueError(\"Arrays must have the same shape\")\n",
    "\n",
    "    # Degrees of freedom = number of rows - 1\n",
    "    dof = len(observed) - 1\n",
    "\n",
    "    zeros_mask = (observed != 0)\n",
    "    if observed.any() == 0:\n",
    "        print('observed data contains zeros')\n",
    "    \n",
    "\n",
    "    # Compute chi-squared statistic\n",
    "    if err is None:\n",
    "        chi2_value = np.sum((observed[zeros_mask] - expected[zeros_mask]) ** 2 / observed[zeros_mask])\n",
    "    else:\n",
    "        chi2_value = np.sum((observed[zeros_mask] - expected[zeros_mask]) ** 2 / err[zeros_mask]**2)\n",
    "\n",
    "    # Calculate p-value\n",
    "    p_value = chi2.sf(chi2_value, dof)\n",
    "    \n",
    "    return chi2_value, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_events(df):\n",
    "    \"\"\"\n",
    "    Group specified indices in the HESE-12 dataset and update energy centers.\n",
    "    Groups (0,1), (14,15), and (16,17,18,19) respectively.\n",
    "    Uses geometric mean for energy centers since bins are in logspace.\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe\n",
    "    grouped_df = df.copy()\n",
    "    # Create a mask for the indices we want to keep\n",
    "    zeros_index = [0, 14, 16, 18, 19]\n",
    "    \n",
    "    # Energy centers for the grouped bins\n",
    "    energy_center_01 = (df.index[0] * df.index[1]) ** 0.5\n",
    "    energy_center_1415 = (df.index[14] * df.index[15]) ** 0.5\n",
    "    energy_center_1619 = (df.index[16] * df.index[17] * df.index[18] * df.index[19]) ** 0.25\n",
    "    \n",
    "    # Events for the grouped bins\n",
    "    events_01 = grouped_df.iloc[0]['events'] + grouped_df.iloc[1]['events']\n",
    "    events_1415 = grouped_df.iloc[14]['events'] + grouped_df.iloc[15]['events']\n",
    "    events_1619 = grouped_df.iloc[16]['events'] + grouped_df.iloc[17]['events'] + grouped_df.iloc[18]['events'] + grouped_df.iloc[19]['events']\n",
    "    #print(events_01, events_1415, events_1619)\n",
    "    # Update the dataframe\n",
    "    index = grouped_df.index.values\n",
    "    index[1] = energy_center_01\n",
    "    index[15] = energy_center_1415\n",
    "    index[17] = energy_center_1619\n",
    "    index = np.delete(index, zeros_index)  \n",
    "    events = grouped_df['events'].values\n",
    "    events[1] = events_01\n",
    "    events[15] = events_1415\n",
    "    events[17] = events_1619\n",
    "    events = np.delete(events, zeros_index)\n",
    "    \n",
    "    grouped_df_new = pd.DataFrame({'events': events}, index=index)\n",
    "    #print(grouped_df_new)\n",
    "\n",
    "    return grouped_df_new\n",
    "\n",
    "\n",
    "hese12_grouped_df = group_events(hese12_events_df)\n",
    "background_grouped_df = group_events(background_df)\n",
    "\n",
    "# Subtract the background events from the HESE12 data, so that if the background is large, it will show in the chi2.\n",
    "observed_signal = hese12_grouped_df['events'].values - background_grouped_df['events'].values\n",
    "print(observed_signal)\n",
    "print('total observed signal events', observed_signal.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_phi = np.logspace(-4, 0, num=10)\n",
    "M_phi = np.logspace(np.log10(4*1e-1), np.log10(2*1e2), num=10)\n",
    "chi2_grid = np.zeros(shape=(len(g_phi), len(M_phi)))\n",
    "\n",
    "evolver = nuSIprop.pyprop(mphi = M_phi[0]*1e6, # Mediator mass [eV]\n",
    "\t\t\t  g = g_phi[0], # Coupling\n",
    "\t\t\t  mntot = 0.1, # Sum of neutrino masses [eV]\n",
    "\t\t\t  si = si_grid[0], # Spectral index\n",
    "\t\t\t  norm = norm, # Normalization of the free-streaming flux at 100 TeV [Default = 1]\n",
    "\t\t\t  majorana = True, # Majorana neutrinos? [Default = True]\n",
    "\t\t\t  non_resonant = True, # Include non s-channel contributions? Relevant for couplings g>~0.1 [Default = True]\n",
    "\t\t\t  normal_ordering = True, # Normal neutrino mass ordering? [Default = True]\n",
    "\t\t\t  N_bins_E = 300, # Number of energy bins, uniformly distributed in log space [Default = 300]\n",
    "\t\t\t  lEmin = 13, # log_10 (E_min/eV) [Default = 13]\n",
    "\t\t\t  lEmax = 16, # log_10 (E_max/eV) [Default = 17]\n",
    "\t\t\t  zmax = 5, # Largest redshift at which sources are included [Default = 5]\n",
    "\t\t\t  flav = 2, # Flavor of interacting neutrinos [0=e, 1=mu, 2=tau. Default = 2]\n",
    "\t\t\t  phiphi = False # Consider double-scalar production? If set to true, the files xsec/alpha_phiphi.bin and xsec/alphatilde_phiphi.bin must exist [Default = False]\n",
    "                          )\n",
    "evolver.evolve()\n",
    "flx = evolver.get_flux_fla()\n",
    "energies = evolver.get_energies()\n",
    "bin_edges_high_resolution = bin_centers_to_edges(energies)\n",
    "delta_E = np.diff(bin_edges_high_resolution)    # Delta E in eV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g_idx, g in enumerate(g_phi):\n",
    "    for M_idx, M in enumerate(M_phi):\n",
    "        chi2_si = []\n",
    "        for si_idx, si_ in enumerate(si_grid):\n",
    "            #print(f'g = {g}, M = {M}, si = {si_}')\n",
    "\n",
    "            with SuppressOutput():\n",
    "                evolver.set_parameters(g=g, mphi=M*1e6, si=si_)\n",
    "                evolver.evolve()\n",
    "\n",
    "            flx = evolver.get_flux_fla()\n",
    "            flx_df = pd.DataFrame(flx.T, index=evolver.get_energies(), columns=['nu_e', 'nu_mu', 'nu_tau'])\n",
    "            flx_df.index = flx_df.index / 1e9    # Convert to [GeV] to align with eff_df. \n",
    "\n",
    "            # norm = 1e-4 to account for cm to m conversion\n",
    "            nuSIprop_df = total_events(flx=effective_area_df, eff=flx_df, livetime=livetime12, norm=1e-4, delta_E=delta_E)\n",
    "            nuSIprop_events = nuSIprop_df['total_events']\n",
    "            nuSIprop_smeared = apply_energy_smearing(energies=nuSIprop_df.index.values, events=nuSIprop_events.values, resolution=0.1)\n",
    "            \n",
    "            # Bin the nuSIprop events according to the low resolution energy bins, to be compared with the HESE12 data.\n",
    "            # Group the nuSIprop events manually, as equal to the HESE12 data\n",
    "            # to avoid numerical issues from zeros in chi2 calculation.\n",
    "            nuSIprop_binned_events, _ = np.histogram(a=nuSIprop_df.index.values, weights=nuSIprop_events.values, bins=energy_bins_low_resolution)\n",
    "            nuSIprop_binned_df = pd.DataFrame(nuSIprop_binned_events, index=energy_centers_low_resolution, columns=['events'])\n",
    "            nuSIprop_grouped_df = group_events(nuSIprop_binned_df)\n",
    "            assert np.round(nuSIprop_grouped_df['events'].sum(), 10) == np.round(nuSIprop_binned_df['events'].sum(), 10)\n",
    "            #print(nuSIprop_grouped_df['events'].values)\n",
    "            \n",
    "            # Add the background events to the nuSIprop events. \n",
    "            #predicted = nuSIprop_grouped_df['events'].values + background_grouped_df['events'].values\n",
    "            #print('total predicted events', predicted.sum())\n",
    "\n",
    "            # Compute the chi2 value for the given g, M and si.\n",
    "            chi2_, p_value = compute_chi2(observed=observed_signal, expected=nuSIprop_grouped_df['events'].values)\n",
    "            chi2_si.append(chi2_)\n",
    "\n",
    "        print('chi2_si', chi2_si)\n",
    "        chi2_grid[g_idx, M_idx] = np.min(chi2_si)\n",
    "        si_min = si_grid[np.argmin(chi2_si)]\n",
    "        print(f'Minimum si for g={g}, M={M}: si = {si_min}')\n",
    "        print('chi2_grid', chi2_grid)\n",
    "        si_marginalized.append(si_min)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nusiprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
